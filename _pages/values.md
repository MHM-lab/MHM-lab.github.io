---
permalink: /values/
title: "Values"
---

The lab values are listed below.

## Attentive, kind, and honest in communication

Communication is one of the most difficult, yet one of the most important interpersonal skills. Skillful communication can be cultivated. We try to foster a laboratory based on attentive, kind, and honest communication. We will dedicate some time to think about what it means for us individually and as a group and support each other in becoming better communicators with ourselves and each other.

## Celebrate and support each other 

While there is awareness that the science of today rewards the individual rather than the group, we rejoice in the success of others. We have limited influence on current scientific reward systems, therefore it is important to acknowledge that we are part of a collective striving towards a larger goal. Without the people in our environment nothing is possible, and nothing would be achieved.

## Embrace diversity

We value diversity and try to minimise biases. This is not always easy therefore we keep each other in check when unconscious biases, false beliefs, or another sneaky mind-blindness maybe at play. Our goal is to achieve equality of opportunity.

## Acknowledge and learn from failure(s)

We help each other failing towards our goals and acknowledge that every new path requires trial and error. This is the foundation of learning.

## Statement on Artifical Intelligence 

We focus on ***narrow AI-systems*** designed to solve concrete problems—rather than what is often called “general AI.” The idea that “once we solve intelligence, we solve everything else” strikes me as hubris.
<br>
<br>
In dominance hierarchies, individuals with lower moral standards often rise disproportionately. Psychopaths, for instance, make up ~1% of the general population but are estimated at up to ~20% in positions of power, as history and many current world leaders illustrate. Those who bind themselves to ethical principles thus most humans —e.g. Kant’s— are less competitive in such struggles, unless they can compensate, for instance, with extraordinary intelligence. If we impose strict guardrails on some AI systems while others remain unconstrained, the unconstrained ones may dominate, especially as intelligence across systems will converge over time. Since I see no evidence that higher intelligence correlates with moral action, this looks like an unsolvable problem. Please convince me otherwise.
<br>
<br>
Our lab works on narrow AI that hopefully helps people, while also developing better tools to understand AI. Whether AGI is possible remains an open question — but not one I have any interest in pursuing.
<br>
<br>
Large Language Models (LLMs) are one such narrow AI application and a useful tool! Here is our [lab’s policy on the use of LLMs](https://mhm-lab.github.io/use_LLMs/).
