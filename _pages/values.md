---
permalink: /values/
title: "Values"
---

The lab values are listed below.

## Attentive, kind, and honest in communication

Communication is one of the most difficult, yet one of the most important interpersonal skills. Skillful communication can be cultivated. We try to foster a laboratory based on attentive, kind, and honest communication. We will dedicate some time to think about what it means for us individually and as a group and support each other in becoming better communicators with ourselves and each other.

## Celebrate and support each other 

While there is awareness that the science of today rewards the individual rather than the group, we rejoice in the success of others. We have limited influence on current scientific reward systems, therefore it is important to acknowledge that we are part of a collective striving towards a larger goal. Without the people in our environment nothing is possible, and nothing would be achieved.

## Embrace diversity

We value diversity and try to minimise biases. This is not always easy therefore we keep each other in check when unconscious biases, false beliefs, or another sneaky mind-blindness maybe at play. Our goal is to achieve equality of opportunity.

## Acknowledge and learn from failure(s)

We help each other failing towards our goals and acknowledge that every new path requires trial and error. This is the foundation of learning.

## Statement on Artifical Intelligence 

We focus on ***narrow Artificial Intelligence (AI)*** designed to solve concrete problems, rather than what is often called Artificial General Intelligence (AGI). In dominance hierarchies, individuals with lower moral standards often rise disproportionately. Psychopaths, for example, represent ~1% of the general population but up to ~4% of those in power, as history and some current leaders illustrate. Those who commit themselves to ethical principles generally strive to act morally, even when doing so comes at significant personal cost. As a result, they may be less competitive, unless compensated by exceptional intelligence, creativity, or other distinguishing strengths. If some AGI systems were bound by strict ethical guardrails, provided possible at all, while others remained unconstrained, the latter would likely dominate. In artificial systems, abilities converge over time through shared weights, mutual learning, and copying. It is more prevalent than in biological systems, as it is generally easier to achieve. Yet even if some world leaders might one day try to clone themselves, they could never replicate their experience, a defining element of personality that no genetic copy can reproduce. Returning to the argument, if we view ethical guardrails as constraints, they can quickly turn into handicaps. Even if an ethical AI system prevailed at first, it could ultimately be displaced by a less ethical one that simply copies and adapts. Since greater intelligence does not appear to correlate with stronger ethics, unconstrained systems would almost inevitably dominate. In humans, ethical behavior is reinforced as groups would not function without trust, reciprocity and acts of kindness. Artificial systems, however, face no such constrains: they can be copied, scaled, and deployed across time and space without restriction, making the dominance of a single unconstrained system far more likely. Therefore, we utelize and develop narrow AI that can help humans or we invest our time into tools or technology to better understand intelligent biological and artificial systems.
<br>
<br>
Large Language Models (LLMs) are currently a narrow AI application, despite claims to the contrary, and a useful tool! Here is our [labâ€™s policy on the use of LLMs](https://mhm-lab.github.io/use_LLMs/).
