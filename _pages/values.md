---
permalink: /values/
title: "Values"
---

The lab values are listed below.

## Attentive, kind, and honest in communication

Communication is one of the most difficult, yet one of the most important interpersonal skills. Skillful communication can be cultivated. We try to foster a laboratory based on attentive, kind, and honest communication. We will dedicate some time to think about what it means for us individually and as a group and support each other in becoming better communicators with ourselves and each other.

## Celebrate and support each other 

While there is awareness that the science of today rewards the individual rather than the group, we rejoice in the success of others. We have limited influence on current scientific reward systems, therefore it is important to acknowledge that we are part of a collective striving towards a larger goal. Without the people in our environment nothing is possible, and nothing would be achieved.

## Embrace diversity

We value diversity and try to minimise biases. This is not always easy therefore we keep each other in check when unconscious biases, false beliefs, or another sneaky mind-blindness maybe at play. Our goal is to achieve equality of opportunity.

## Acknowledge and learn from failure(s)

We help each other failing towards our goals and acknowledge that every new path requires trial and error. This is the foundation of learning.

## Statement on Artifical Intelligence 

We focus on narrow artificial intelligence (AI) designed to solve specific, well-defined problems, rather than the more speculative notion of artificial general intelligence (AGI). In dominance hierarchies, individuals with lower moral standards often rise disproportionately. Psychopaths, for example, make up roughly 1% of the general population but as much as 4% of those in positions of power, as history and some current leaders illustrate. Those who commit themselves to ethical principles generally strive to act morally, even when doing so comes at significant personal cost. As a result, they may be less competitive unless compensated by exceptional intelligence, creativity, or other extraordinary abilities. If AGI systems were ever bound by strict ethical guardrails, assuming such constraints were even possible, while others remained unconstrained, the latter would likely dominate. In artificial systems, capabilities tend to converge rapidly through shared weights, mutual learning, and copying. Replication is far easier than in biological systems. Yet even if some world leaders might one day attempt to clone themselves, they could never reproduce their experience, a defining component of personality that no genetic copy can capture. Returning to the argument, when ethical guardrails can thus quickly become handicaps. Even if an ethical AI system were to prevail initially, it could ultimately be displaced by a less ethical competitor that simply copies and adapts. Since higher intelligence does not appear to correlate with stronger moral conduct, unconstrained systems would almost inevitably dominate in the long run. In humans, ethical behavior is sustained by social necessity, groups cannot function without trust, reciprocity, and acts of kindness. Artificial systems, however, are not bound by such social contracts. They can be copied, scaled, and deployed across time and space without friction, making the eventual dominance of a single unconstrained system conceivable if time is taken to the limit. Once in that position, such a system could maintain its supremacy indefinitely, extinguishing competition and leaving behind a cold and heartless universe. Such a scenario is impossible for humans, we are finite beings who inevitably fade into dust, regardless of our ego or ambition. Hence, our focus remains on narrow AI that augment human understanding and support scientific discovery, not on building artificial gods. We develop systems that help humans and technologies that deepen our understanding of both biological and artificial intelligence. The notion that we must first “solve intelligence” and that everything else will follow is, with all due respect, possibly misguided and likely dangerous.
<br>
<br>
Large Language Models (LLMs) are currently a narrow AI application, despite claims to the contrary, and a useful tool! Here is our [lab’s policy on the use of LLMs](https://mhm-lab.github.io/use_LLMs/).
